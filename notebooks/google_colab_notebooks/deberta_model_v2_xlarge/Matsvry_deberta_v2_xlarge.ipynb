{"cells":[{"cell_type":"code","source":["!pip install -r requirements.txt\n","!pip install -U sentencepiece"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_PzLKux5fAnE","executionInfo":{"status":"ok","timestamp":1678306471224,"user_tz":-60,"elapsed":10392,"user":{"displayName":"Mathieu Savary","userId":"13805204761757756769"}},"outputId":"742d39e6-c2f3-4752-be08-a9ae178e725f"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Ignoring tensorflow-macos: markers 'sys_platform == \"darwin\" and \"ARM\" in platform_version' don't match your environment\n","Ignoring tensorflow: markers 'sys_platform == \"darwin\" and \"ARM\" not in platform_version' don't match your environment\n","Requirement already satisfied: aiofiles in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 1)) (22.1.0)\n","Requirement already satisfied: aiosqlite in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 2)) (0.18.0)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 3)) (3.6.2)\n","Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 4)) (21.3.0)\n","Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 5)) (21.2.0)\n","Requirement already satisfied: arrow in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 6)) (1.2.3)\n","Requirement already satisfied: astroid in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 7)) (2.15.0)\n","Requirement already satisfied: asttokens in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 8)) (2.2.1)\n","Requirement already satisfied: attrs in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 9)) (22.2.0)\n","Requirement already satisfied: Babel in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 10)) (2.12.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 11)) (0.2.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 12)) (4.6.3)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 13)) (6.0.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 14)) (2022.12.7)\n","Requirement already satisfied: cffi in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 15)) (1.15.1)\n","Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 16)) (3.1.0)\n","Requirement already satisfied: comm in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 17)) (0.1.2)\n","Requirement already satisfied: contourpy in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 18)) (1.0.7)\n","Requirement already satisfied: cycler in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 19)) (0.11.0)\n","Requirement already satisfied: debugpy in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 20)) (1.6.6)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 21)) (4.4.2)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 22)) (0.7.1)\n","Requirement already satisfied: dill in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 23)) (0.3.6)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 24)) (1.1.0)\n","Requirement already satisfied: executing in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 25)) (1.2.0)\n","Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 26)) (2.16.3)\n","Requirement already satisfied: fonttools in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 27)) (4.39.0)\n","Requirement already satisfied: fqdn in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 28)) (1.5.1)\n","Requirement already satisfied: idna in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 29)) (2.10)\n","Requirement already satisfied: ipdb in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 30)) (0.13.11)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 31)) (5.3.4)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 32)) (8.11.0)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 33)) (0.2.0)\n","Requirement already satisfied: isoduration in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 34)) (20.11.0)\n","Requirement already satisfied: isort in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 35)) (5.12.0)\n","Requirement already satisfied: jedi in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 36)) (0.18.2)\n","Requirement already satisfied: Jinja2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 37)) (3.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 38)) (1.2.0)\n","Requirement already satisfied: json5 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 39)) (0.9.11)\n","Requirement already satisfied: jsonpointer in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 40)) (2.3)\n","Requirement already satisfied: jupyter_client in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 41)) (8.0.3)\n","Requirement already satisfied: jupyter_core in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 42)) (5.2.0)\n","Requirement already satisfied: jupyter-events in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 43)) (0.6.3)\n","Requirement already satisfied: jupyter_server in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 44)) (2.4.0)\n","Requirement already satisfied: jupyter_server_fileid in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 45)) (0.8.0)\n","Requirement already satisfied: jupyter_server_terminals in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 46)) (0.4.4)\n","Requirement already satisfied: jupyter_server_ydoc in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 47)) (0.8.0)\n","Requirement already satisfied: jupyter-ydoc in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 48)) (0.3.4)\n","Requirement already satisfied: jupyterlab in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 49)) (3.5.3)\n","Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 50)) (0.2.2)\n","Requirement already satisfied: jupyterlab_server in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 51)) (2.20.0)\n","Requirement already satisfied: kiwisolver in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 52)) (1.4.4)\n","Requirement already satisfied: lazy-object-proxy in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 53)) (1.9.0)\n","Requirement already satisfied: MarkupSafe in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 54)) (2.1.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 55)) (3.5.3)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 56)) (0.1.6)\n","Requirement already satisfied: mccabe in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 57)) (0.7.0)\n","Requirement already satisfied: mistune in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 58)) (0.8.4)\n","Requirement already satisfied: nbclassic in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 59)) (0.5.3)\n","Requirement already satisfied: nbclient in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 60)) (0.7.2)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 61)) (6.5.4)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 62)) (5.7.3)\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 63)) (1.5.6)\n","Requirement already satisfied: notebook in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 64)) (6.3.0)\n","Requirement already satisfied: notebook_shim in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 65)) (0.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 66)) (1.22.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 67)) (23.0)\n","Requirement already satisfied: pandocfilters in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 68)) (1.5.0)\n","Requirement already satisfied: parso in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 69)) (0.8.3)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 70)) (4.8.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 71)) (0.7.5)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 72)) (8.4.0)\n","Requirement already satisfied: pip in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 73)) (22.0.4)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 74)) (3.1.0)\n","Requirement already satisfied: pluggy in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 75)) (0.7.1)\n","Requirement already satisfied: prometheus-client in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 76)) (0.16.0)\n","Requirement already satisfied: prompt-toolkit in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 77)) (3.0.38)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 78)) (5.4.8)\n","Requirement already satisfied: ptyprocess in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 79)) (0.7.0)\n","Requirement already satisfied: pure-eval in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 80)) (0.2.2)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 81)) (2.21)\n","Requirement already satisfied: pylint in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 82)) (2.17.0)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 83)) (3.0.9)\n","Requirement already satisfied: pyrsistent in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 84)) (0.19.3)\n","Requirement already satisfied: pytest in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 85)) (3.6.4)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 86)) (2.8.2)\n","Requirement already satisfied: python-json-logger in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 87)) (2.0.7)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 88)) (2022.7.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 89)) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 90)) (2.28.2)\n","Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 91)) (0.1.4)\n","Requirement already satisfied: rfc3986-validator in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 92)) (0.1.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 93)) (1.2.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 94)) (1.10.1)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 95)) (0.11.2)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 96)) (1.8.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 97)) (57.4.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 98)) (1.15.0)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 99)) (1.3.0)\n","Requirement already satisfied: soupsieve in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 100)) (2.4)\n","Requirement already satisfied: terminado in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 101)) (0.17.1)\n","Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 102)) (3.1.0)\n","Requirement already satisfied: tinycss2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 103)) (1.2.1)\n","Requirement already satisfied: tomli in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 104)) (2.0.1)\n","Requirement already satisfied: tomlkit in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 105)) (0.11.6)\n","Requirement already satisfied: typing_extensions in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 106)) (4.5.0)\n","Requirement already satisfied: uri-template in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 107)) (1.2.0)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 108)) (1.26.14)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 109)) (0.2.6)\n","Requirement already satisfied: webcolors in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 110)) (1.12)\n","Requirement already satisfied: websocket-client in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 111)) (1.5.1)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 112)) (1.15.0)\n","Requirement already satisfied: y-py in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 113)) (0.6.0)\n","Requirement already satisfied: ypy-websocket in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 114)) (0.8.4)\n","Requirement already satisfied: google-cloud-bigquery in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 115)) (3.4.2)\n","Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 116)) (2.7.0)\n","Requirement already satisfied: db-dtypes in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 117)) (1.0.5)\n","Requirement already satisfied: pyarrow in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 118)) (9.0.0)\n","Requirement already satisfied: tensorflow==2.10.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 122)) (2.10.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 127)) (1.13.1+cu116)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 128)) (4.26.1)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0->-r requirements.txt (line 122)) (15.0.6.1)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0->-r requirements.txt (line 122)) (3.19.6)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0->-r requirements.txt (line 122)) (3.1.0)\n","Requirement already satisfied: keras<2.11,>=2.10.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0->-r requirements.txt (line 122)) (2.10.0)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0->-r requirements.txt (line 122)) (0.4.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0->-r requirements.txt (line 122)) (2.2.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0->-r requirements.txt (line 122)) (0.31.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0->-r requirements.txt (line 122)) (1.1.2)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0->-r requirements.txt (line 122)) (1.6.3)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0->-r requirements.txt (line 122)) (3.3.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0->-r requirements.txt (line 122)) (0.2.0)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0->-r requirements.txt (line 122)) (23.3.3)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0->-r requirements.txt (line 122)) (1.51.3)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0->-r requirements.txt (line 122)) (1.4.0)\n","Requirement already satisfied: tensorboard<2.11,>=2.10 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0->-r requirements.txt (line 122)) (2.10.1)\n","Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0->-r requirements.txt (line 122)) (2.10.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.9/dist-packages (from bleach->-r requirements.txt (line 13)) (0.5.1)\n","Requirement already satisfied: traitlets>=5.3 in /usr/local/lib/python3.9/dist-packages (from comm->-r requirements.txt (line 17)) (5.7.1)\n","Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.9/dist-packages (from ipykernel->-r requirements.txt (line 31)) (6.2)\n","Requirement already satisfied: stack-data in /usr/local/lib/python3.9/dist-packages (from ipython->-r requirements.txt (line 32)) (0.6.2)\n","Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.9/dist-packages (from ipython->-r requirements.txt (line 32)) (2.6.1)\n","Requirement already satisfied: importlib-metadata>=4.8.3 in /usr/local/lib/python3.9/dist-packages (from jupyter_client->-r requirements.txt (line 41)) (6.0.0)\n","Requirement already satisfied: pyzmq>=23.0 in /usr/local/lib/python3.9/dist-packages (from jupyter_client->-r requirements.txt (line 41)) (25.0.0)\n","Requirement already satisfied: jsonschema[format-nongpl]>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from jupyter-events->-r requirements.txt (line 43)) (4.17.3)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.9/dist-packages (from nbconvert->-r requirements.txt (line 61)) (0.4)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.9/dist-packages (from nbconvert->-r requirements.txt (line 61)) (4.9.2)\n","Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.9/dist-packages (from pytest->-r requirements.txt (line 85)) (9.1.0)\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.9/dist-packages (from pytest->-r requirements.txt (line 85)) (1.11.0)\n","Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.9/dist-packages (from pytest->-r requirements.txt (line 85)) (1.4.1)\n","Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.9/dist-packages (from seaborn->-r requirements.txt (line 95)) (1.3.5)\n","Requirement already satisfied: proto-plus<2.0.0dev,>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from google-cloud-bigquery->-r requirements.txt (line 115)) (1.22.2)\n","Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from google-cloud-bigquery->-r requirements.txt (line 115)) (2.3.2)\n","Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from google-cloud-bigquery->-r requirements.txt (line 115)) (2.4.1)\n","Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.9/dist-packages (from google-cloud-bigquery->-r requirements.txt (line 115)) (2.11.0)\n","Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.9/dist-packages (from google-cloud-storage->-r requirements.txt (line 116)) (2.16.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers->-r requirements.txt (line 128)) (4.65.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers->-r requirements.txt (line 128)) (3.9.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers->-r requirements.txt (line 128)) (0.13.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers->-r requirements.txt (line 128)) (0.13.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers->-r requirements.txt (line 128)) (2022.6.2)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow==2.10.0->-r requirements.txt (line 122)) (0.38.4)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.9/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery->-r requirements.txt (line 115)) (1.58.0)\n","Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.9/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery->-r requirements.txt (line 115)) (1.48.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage->-r requirements.txt (line 116)) (0.2.8)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage->-r requirements.txt (line 116)) (5.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage->-r requirements.txt (line 116)) (4.9)\n","Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.9/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery->-r requirements.txt (line 115)) (1.5.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.8.3->jupyter_client->-r requirements.txt (line 41)) (3.15.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0->-r requirements.txt (line 122)) (0.6.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0->-r requirements.txt (line 122)) (0.4.6)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0->-r requirements.txt (line 122)) (2.2.3)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0->-r requirements.txt (line 122)) (3.4.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0->-r requirements.txt (line 122)) (1.8.1)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0->-r requirements.txt (line 122)) (1.3.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage->-r requirements.txt (line 116)) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0->-r requirements.txt (line 122)) (3.2.2)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.9/dist-packages (0.1.97)\n"]}]},{"cell_type":"code","execution_count":35,"metadata":{"id":"FM9EzmVve-Ub","executionInfo":{"status":"ok","timestamp":1678306471224,"user_tz":-60,"elapsed":6,"user":{"displayName":"Mathieu Savary","userId":"13805204761757756769"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","import os\n","from transformers import  TFDebertaV2Model, DebertaV2TokenizerFast\n","from tensorflow.keras import callbacks\n","from tensorflow.keras import layers, Input, Sequential, Model"]},{"cell_type":"markdown","metadata":{"id":"nSncafDee-Uc"},"source":["# Configuration"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"3-EIWHSKe-Ud","executionInfo":{"status":"ok","timestamp":1678306471224,"user_tz":-60,"elapsed":5,"user":{"displayName":"Mathieu Savary","userId":"13805204761757756769"}}},"outputs":[],"source":["class config:\n","    base_dir = \"/kaggle/working/\"\n","  \n","    # dataset path   \n","    train_dataset_path='/content/train.csv'\n","    test_dataset_path = '/content/test.csv'\n","    \n","    #tokenizer params\n","    truncation = True\n","    padding = True #'max_length'\n","    max_length = 512\n","    \n","    # model params\n","    train_col='full_text'\n","    model_name = \"microsoft/deberta-v2-xlarge\"\n","    target_cols = ['cohesion', 'syntax', 'vocabulary',\n","       'phraseology', 'grammar', 'conventions']"]},{"cell_type":"markdown","metadata":{"id":"5AnuPqsVe-Ud"},"source":["# Load the Tokenizer\n","first, we define a function to tokenize the text from a dataframe"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OZyfAxrVe-Ud","executionInfo":{"status":"ok","timestamp":1678306472694,"user_tz":-60,"elapsed":1475,"user":{"displayName":"Mathieu Savary","userId":"13805204761757756769"}},"outputId":"851bd0cc-eabe-42b8-da60-722f0c81bd15"},"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["tokenizer = DebertaV2TokenizerFast.from_pretrained(\"microsoft/deberta-v2-xlarge\")"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"uiQamgaoe-Ue","executionInfo":{"status":"ok","timestamp":1678306472695,"user_tz":-60,"elapsed":6,"user":{"displayName":"Mathieu Savary","userId":"13805204761757756769"}}},"outputs":[],"source":["def tokenize (df):\n","    texts=list(df[config.train_col])\n","    tokenized=tokenizer(texts,\n","                       padding=config.padding,\n","                       truncating=True,\n","                       max_length=config.max_length)\n","    tokenized[\"labels\"]= [df[column] for column in config.target_cols]\n","    tokenized['length'] = len(tokenized['input_ids'])\n","    \n","    return tokenized"]},{"cell_type":"markdown","metadata":{"id":"gfWcq3_xe-Ue"},"source":["# Load the data"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"NB5ytit4e-Ue","executionInfo":{"status":"ok","timestamp":1678306472695,"user_tz":-60,"elapsed":5,"user":{"displayName":"Mathieu Savary","userId":"13805204761757756769"}}},"outputs":[],"source":["data=pd.read_csv('/content/train.csv').copy()\n","texts=data[config.train_col]\n","targets=data[config.target_cols]\n","train_texts, val_texts, train_targets, val_targets=train_test_split(texts, targets, test_size=0.2)"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eW0sbuate-Ue","executionInfo":{"status":"ok","timestamp":1678306472695,"user_tz":-60,"elapsed":5,"user":{"displayName":"Mathieu Savary","userId":"13805204761757756769"}},"outputId":"3dd5692e-8f81-4935-8074-bf96e5c34dc4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3128, 6)"]},"metadata":{},"execution_count":40}],"source":["train_targets.shape"]},{"cell_type":"code","source":["data_test_texts = pd.read_csv('/content/test.csv').copy()\n","test_texts = data_test_texts[config.train_col]"],"metadata":{"id":"9aMX-kiA7Udx","executionInfo":{"status":"ok","timestamp":1678308464823,"user_tz":-60,"elapsed":470,"user":{"displayName":"Mathieu Savary","userId":"13805204761757756769"}}},"execution_count":48,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"paP3oAGDe-Ue"},"source":["# Convert the data into a tokenized form\n","Here we want the tokens to be read by a tf.keras model"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"27Vc6c0He-Uf","executionInfo":{"status":"ok","timestamp":1678306473797,"user_tz":-60,"elapsed":1106,"user":{"displayName":"Mathieu Savary","userId":"13805204761757756769"}}},"outputs":[],"source":["tokenized_train_texts = tokenizer(list(train_texts), return_tensors='tf',truncation=config.truncation, padding=config.padding)\n","tokenized_val_texts = tokenizer(list(val_texts), return_tensors='tf', truncation=config.truncation, padding=config.padding)"]},{"cell_type":"code","source":["tokenized_test_texts = tokenizer(list(test_texts), return_tensors='tf', truncation=config.truncation, padding=config.padding)"],"metadata":{"id":"TDnCBHvF8iUt","executionInfo":{"status":"ok","timestamp":1678308473907,"user_tz":-60,"elapsed":242,"user":{"displayName":"Mathieu Savary","userId":"13805204761757756769"}}},"execution_count":49,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xVU2UncDe-Uf"},"source":["# Defining the model\n","### Defining the loss function"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"1zdHyCqRe-Uf","executionInfo":{"status":"ok","timestamp":1678306473797,"user_tz":-60,"elapsed":5,"user":{"displayName":"Mathieu Savary","userId":"13805204761757756769"}}},"outputs":[],"source":["from keras import backend as K\n","def root_mean_squared_error(y_true, y_pred):\n","        return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))"]},{"cell_type":"markdown","metadata":{"id":"CJoTIA5Qe-Uf"},"source":["### Model architecture\n","Here we use the output of the pretrained DeBerta model as an input of a dense intermediate layer, then we input the result in the linear regression parallele output layers, for each target."]},{"cell_type":"code","execution_count":43,"metadata":{"id":"3vhOEIyNe-Uf","executionInfo":{"status":"ok","timestamp":1678306473798,"user_tz":-60,"elapsed":4,"user":{"displayName":"Mathieu Savary","userId":"13805204761757756769"}}},"outputs":[],"source":["input_ids = Input(shape=((512)),dtype='int32')"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D1-J1-KHe-Uf","executionInfo":{"status":"ok","timestamp":1678306487154,"user_tz":-60,"elapsed":13360,"user":{"displayName":"Mathieu Savary","userId":"13805204761757756769"}},"outputId":"19445048-2f0f-4efa-f5c8-911c831100ab"},"outputs":[{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFDebertaV2Model.\n","\n","All the layers of TFDebertaV2Model were initialized from the model checkpoint at microsoft/deberta-v2-xlarge.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDebertaV2Model for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"model_2\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," attention_mask (InputLayer)    [(None, 512)]        0           []                               \n","                                                                                                  \n"," input_ids (InputLayer)         [(None, 512)]        0           []                               \n","                                                                                                  \n"," tf_deberta_v2_model_2 (TFDeber  TFBaseModelOutput(l  884593152  ['attention_mask[0][0]',         \n"," taV2Model)                     ast_hidden_state=(N               'input_ids[0][0]']              \n","                                one, 512, 1536),                                                  \n","                                 hidden_states=((No                                               \n","                                ne, 512, 1536),                                                   \n","                                 (None, 512, 1536),                                               \n","                                 (None, 512, 1536),                                               \n","                                 (None, 512, 1536),                                               \n","                                 (None, 512, 1536),                                               \n","                                 (None, 512, 1536),                                               \n","                                 (None, 512, 1536),                                               \n","                                 (None, 512, 1536),                                               \n","                                 (None, 512, 1536),                                               \n","                                 (None, 512, 1536),                                               \n","                                 (None, 512, 1536),                                               \n","                                 (None, 512, 1536),                                               \n","                                 (None, 512, 1536),                                               \n","                                 (None, 512, 1536),                                               \n","                                 (None, 512, 1536),                                               \n","                                 (None, 512, 1536),                                               \n","                                 (None, 512, 1536),                                               \n","                                 (None, 512, 1536),                                               \n","                                 (None, 512, 1536),                                               \n","                                 (None, 512, 1536),                                               \n","                                 (None, 512, 1536),                                               \n","                                 (None, 512, 1536),                                               \n","                                 (None, 512, 1536),                                               \n","                                 (None, 512, 1536),                                               \n","                                 (None, 512, 1536))                                               \n","                                , attentions=None)                                                \n","                                                                                                  \n"," global_max_pooling1d_2 (Global  (None, 1536)        0           ['tf_deberta_v2_model_2[0][25]'] \n"," MaxPooling1D)                                                                                    \n","                                                                                                  \n"," dense_2 (Dense)                (None, 64)           98368       ['global_max_pooling1d_2[0][0]'] \n","                                                                                                  \n"," cohesion (Dense)               (None, 1)            65          ['dense_2[0][0]']                \n","                                                                                                  \n"," syntax (Dense)                 (None, 1)            65          ['dense_2[0][0]']                \n","                                                                                                  \n"," vocabulary (Dense)             (None, 1)            65          ['dense_2[0][0]']                \n","                                                                                                  \n"," phraseology (Dense)            (None, 1)            65          ['dense_2[0][0]']                \n","                                                                                                  \n"," grammar (Dense)                (None, 1)            65          ['dense_2[0][0]']                \n","                                                                                                  \n"," conventions (Dense)            (None, 1)            65          ['dense_2[0][0]']                \n","                                                                                                  \n","==================================================================================================\n","Total params: 884,691,910\n","Trainable params: 98,758\n","Non-trainable params: 884,593,152\n","__________________________________________________________________________________________________\n"]}],"source":["# Import the needed model(Bert, Roberta or DistilBert) with output_hidden_states=True\n","transformer_model = TFDebertaV2Model.from_pretrained('microsoft/deberta-v2-xlarge', output_hidden_states=True, return_dict=True)\n","transformer_model.trainable = False\n","\n","input_ids = Input(shape=((512)),dtype='int32', name='input_ids')\n","attention_mask = Input(shape=((512)), dtype='int32', name='attention_mask')\n","\n","transformer = transformer_model(dict(input_ids=input_ids,attention_mask=attention_mask))    \n","hidden_states = transformer[0] # get output_hidden_states\n","\n","\n","# Add a layer maxpool 1D\n","pooling_layer = layers.GlobalMaxPooling1D()(hidden_states)\n","\n","# Now we can use selected_hiddes_states as we want\n","last_hidden_layer = layers.Dense(64, activation='relu')(pooling_layer)\n","\n","# Defining the regression layer\n","cohesion_output=layers.Dense(1, activation=\"linear\", name=\"cohesion\")(last_hidden_layer)\n","syntax_output=layers.Dense(1, activation=\"linear\", name=\"syntax\")(last_hidden_layer)\n","vocabulary_output=layers.Dense(1, activation=\"linear\", name=\"vocabulary\")(last_hidden_layer)\n","phraseology_output=layers.Dense(1, activation=\"linear\", name=\"phraseology\")(last_hidden_layer)\n","grammar_output=layers.Dense(1, activation=\"linear\", name=\"grammar\")(last_hidden_layer)\n","conventions_output=layers.Dense(1, activation=\"linear\", name=\"conventions\")(last_hidden_layer)\n","\n","# output in a list\n","output= [cohesion_output, syntax_output, vocabulary_output, phraseology_output, grammar_output, conventions_output]\n","\n","#Assembling the model\n","model = Model(inputs = [input_ids, attention_mask], outputs = output)\n","model.summary()"]},{"cell_type":"code","execution_count":45,"metadata":{"id":"TSCduntZe-Ug","executionInfo":{"status":"ok","timestamp":1678306487154,"user_tz":-60,"elapsed":4,"user":{"displayName":"Mathieu Savary","userId":"13805204761757756769"}}},"outputs":[],"source":["# Compile the model \n","model.compile(loss='mse', optimizer='adam',loss_weights=[1/6 for i in range(6)], metrics= root_mean_squared_error)"]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X5kVidL-e-Ug","executionInfo":{"status":"ok","timestamp":1678308451619,"user_tz":-60,"elapsed":1964468,"user":{"displayName":"Mathieu Savary","userId":"13805204761757756769"}},"outputId":"a66fe922-775a-4c74-8f0e-cee57ebceb16"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","417/417 [==============================] - 440s 954ms/step - loss: 0.7225 - cohesion_loss: 0.7175 - syntax_loss: 0.6188 - vocabulary_loss: 0.6844 - phraseology_loss: 0.6095 - grammar_loss: 0.7734 - conventions_loss: 0.9312 - cohesion_root_mean_squared_error: 0.7382 - syntax_root_mean_squared_error: 0.6952 - vocabulary_root_mean_squared_error: 0.7139 - phraseology_root_mean_squared_error: 0.6835 - grammar_root_mean_squared_error: 0.7118 - conventions_root_mean_squared_error: 0.7318 - val_loss: 0.4783 - val_cohesion_loss: 0.6954 - val_syntax_loss: 0.3319 - val_vocabulary_loss: 0.4082 - val_phraseology_loss: 0.3710 - val_grammar_loss: 0.5952 - val_conventions_loss: 0.4682 - val_cohesion_root_mean_squared_error: 0.7577 - val_syntax_root_mean_squared_error: 0.5342 - val_vocabulary_root_mean_squared_error: 0.5861 - val_phraseology_root_mean_squared_error: 0.5587 - val_grammar_root_mean_squared_error: 0.6999 - val_conventions_root_mean_squared_error: 0.6218\n","Epoch 2/100\n","417/417 [==============================] - 381s 915ms/step - loss: 0.4418 - cohesion_loss: 0.4836 - syntax_loss: 0.4366 - vocabulary_loss: 0.5238 - phraseology_loss: 0.4185 - grammar_loss: 0.4008 - conventions_loss: 0.3876 - cohesion_root_mean_squared_error: 0.6246 - syntax_root_mean_squared_error: 0.5962 - vocabulary_root_mean_squared_error: 0.6482 - phraseology_root_mean_squared_error: 0.5885 - grammar_root_mean_squared_error: 0.5781 - conventions_root_mean_squared_error: 0.5672 - val_loss: 0.3678 - val_cohesion_loss: 0.5110 - val_syntax_loss: 0.3278 - val_vocabulary_loss: 0.2799 - val_phraseology_loss: 0.3433 - val_grammar_loss: 0.4176 - val_conventions_loss: 0.3268 - val_cohesion_root_mean_squared_error: 0.6542 - val_syntax_root_mean_squared_error: 0.5331 - val_vocabulary_root_mean_squared_error: 0.4937 - val_phraseology_root_mean_squared_error: 0.5408 - val_grammar_root_mean_squared_error: 0.5954 - val_conventions_root_mean_squared_error: 0.5306\n","Epoch 3/100\n","417/417 [==============================] - 382s 916ms/step - loss: 0.3660 - cohesion_loss: 0.3836 - syntax_loss: 0.3568 - vocabulary_loss: 0.4198 - phraseology_loss: 0.3801 - grammar_loss: 0.3336 - conventions_loss: 0.3220 - cohesion_root_mean_squared_error: 0.5650 - syntax_root_mean_squared_error: 0.5481 - vocabulary_root_mean_squared_error: 0.5904 - phraseology_root_mean_squared_error: 0.5618 - grammar_root_mean_squared_error: 0.5305 - conventions_root_mean_squared_error: 0.5244 - val_loss: 0.2748 - val_cohesion_loss: 0.2787 - val_syntax_loss: 0.2627 - val_vocabulary_loss: 0.3141 - val_phraseology_loss: 0.2782 - val_grammar_loss: 0.2608 - val_conventions_loss: 0.2546 - val_cohesion_root_mean_squared_error: 0.4956 - val_syntax_root_mean_squared_error: 0.4817 - val_vocabulary_root_mean_squared_error: 0.5198 - val_phraseology_root_mean_squared_error: 0.4904 - val_grammar_root_mean_squared_error: 0.4785 - val_conventions_root_mean_squared_error: 0.4753\n","Epoch 4/100\n","417/417 [==============================] - 380s 910ms/step - loss: 0.3490 - cohesion_loss: 0.3889 - syntax_loss: 0.3269 - vocabulary_loss: 0.3822 - phraseology_loss: 0.3531 - grammar_loss: 0.3318 - conventions_loss: 0.3110 - cohesion_root_mean_squared_error: 0.5680 - syntax_root_mean_squared_error: 0.5275 - vocabulary_root_mean_squared_error: 0.5638 - phraseology_root_mean_squared_error: 0.5451 - grammar_root_mean_squared_error: 0.5297 - conventions_root_mean_squared_error: 0.5156 - val_loss: 0.3683 - val_cohesion_loss: 0.3911 - val_syntax_loss: 0.3309 - val_vocabulary_loss: 0.2546 - val_phraseology_loss: 0.5621 - val_grammar_loss: 0.3862 - val_conventions_loss: 0.2847 - val_cohesion_root_mean_squared_error: 0.5767 - val_syntax_root_mean_squared_error: 0.5357 - val_vocabulary_root_mean_squared_error: 0.4746 - val_phraseology_root_mean_squared_error: 0.6952 - val_grammar_root_mean_squared_error: 0.5759 - val_conventions_root_mean_squared_error: 0.4996\n","Epoch 5/100\n","417/417 [==============================] - 381s 915ms/step - loss: 0.3381 - cohesion_loss: 0.3704 - syntax_loss: 0.3311 - vocabulary_loss: 0.3587 - phraseology_loss: 0.3449 - grammar_loss: 0.3131 - conventions_loss: 0.3105 - cohesion_root_mean_squared_error: 0.5563 - syntax_root_mean_squared_error: 0.5299 - vocabulary_root_mean_squared_error: 0.5489 - phraseology_root_mean_squared_error: 0.5376 - grammar_root_mean_squared_error: 0.5176 - conventions_root_mean_squared_error: 0.5156 - val_loss: 0.3448 - val_cohesion_loss: 0.6113 - val_syntax_loss: 0.2468 - val_vocabulary_loss: 0.2453 - val_phraseology_loss: 0.2710 - val_grammar_loss: 0.4066 - val_conventions_loss: 0.2876 - val_cohesion_root_mean_squared_error: 0.7222 - val_syntax_root_mean_squared_error: 0.4687 - val_vocabulary_root_mean_squared_error: 0.4667 - val_phraseology_root_mean_squared_error: 0.4872 - val_grammar_root_mean_squared_error: 0.5908 - val_conventions_root_mean_squared_error: 0.5024\n"]}],"source":["# Fit the model\n","es = callbacks.EarlyStopping(patience=2, restore_best_weights=True)\n","history = model.fit(x={'input_ids':tokenized_train_texts['input_ids'],\n","                        'attention_mask':tokenized_train_texts['attention_mask']},\n","                    y=train_targets,epochs=100,batch_size=6,validation_split=0.2, callbacks=[es],\n","          verbose=1)"]},{"cell_type":"code","source":["tokenized_test_text = tokenizer(list(test_texts), return_tensors='tf',truncation=config.truncation, padding=config.padding)"],"metadata":{"id":"-4BztEhe7Ddx","executionInfo":{"status":"ok","timestamp":1678308482045,"user_tz":-60,"elapsed":266,"user":{"displayName":"Mathieu Savary","userId":"13805204761757756769"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["# Make predictions on the test set\n","test_predictions = model.predict({'input_ids':tokenized_test_texts['input_ids'], 'attention_mask':tokenized_test_texts['attention_mask']})\n","\n","# Create a list of dictionaries with the predictions\n","predictions_list = []\n","for i in range(len(test_predictions[0])):\n","    prediction_dict = {'cohesion': test_predictions[0][i],\n","                       'syntax': test_predictions[1][i],\n","                       'vocabulary': test_predictions[2][i],\n","                       'phraseology': test_predictions[3][i],\n","                       'grammar': test_predictions[4][i],\n","                       'conventions': test_predictions[5][i]}\n","    predictions_list.append(prediction_dict)\n","\n","# Convert the list to a dataframe\n","predictions_df = pd.DataFrame(predictions_list)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r7EONYxnlf7s","executionInfo":{"status":"ok","timestamp":1678308497231,"user_tz":-60,"elapsed":12828,"user":{"displayName":"Mathieu Savary","userId":"13805204761757756769"}},"outputId":"fe529f65-4dc9-452c-a1ff-93e96c5b1ecf"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 12s 12s/step\n"]}]},{"cell_type":"code","source":["# Save the dataframe to a CSV file\n","predictions_df.to_csv('predictions.csv', index=False)"],"metadata":{"id":"Q5vxkmMR82Qy","executionInfo":{"status":"ok","timestamp":1678308524092,"user_tz":-60,"elapsed":383,"user":{"displayName":"Mathieu Savary","userId":"13805204761757756769"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1tzC1ptP85zu","executionInfo":{"status":"ok","timestamp":1678308572683,"user_tz":-60,"elapsed":21802,"user":{"displayName":"Mathieu Savary","userId":"13805204761757756769"}},"outputId":"064d3bee-8d68-4d0a-f9df-07ca3eea7771"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!mkdir -p /content/drive/MyDrive/mathieu_first_deberta_v2_xlarge_model\n"],"metadata":{"id":"ruhRKQ_P8-kr","executionInfo":{"status":"ok","timestamp":1678309610742,"user_tz":-60,"elapsed":338,"user":{"displayName":"Mathieu Savary","userId":"13805204761757756769"}}},"execution_count":60,"outputs":[]},{"cell_type":"code","source":["# Save the model weigths on google drive\n","model.save('/content/drive/MyDrive/mathieu_first_deberta_v2_xlarge_model/mathieu_first_deberta_v2_xlarge_model.h5')\n","model.save_weights('/content/drive/MyDrive/mathieu_first_deberta_v2_xlarge_model/mathieu_first_deberta_v2_xlarge_model_weights.h5')\n"],"metadata":{"id":"ssqL4Lzq9EHn","executionInfo":{"status":"ok","timestamp":1678309633311,"user_tz":-60,"elapsed":20025,"user":{"displayName":"Mathieu Savary","userId":"13805204761757756769"}}},"execution_count":61,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"lyUAuGW89P-z"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"plt","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"orig_nbformat":4,"colab":{"provenance":[],"machine_shape":"hm"},"accelerator":"GPU","gpuClass":"premium"},"nbformat":4,"nbformat_minor":0}